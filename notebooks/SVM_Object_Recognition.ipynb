{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ SVM Object Recognition\n",
    "## Bachelor's Thesis - Data Analytics Final Project\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Data Analytics Student  \n",
    "**Date:** January 2026  \n",
    "**Topic:** Support Vector Machine for Image Classification\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction & Theory](#1-introduction)\n",
    "2. [Data Loading & Exploration](#2-data-loading)\n",
    "3. [Feature Engineering (HOG)](#3-feature-engineering)\n",
    "4. [Model Training](#4-model-training)\n",
    "5. [Hyperparameter Tuning](#5-hyperparameter-tuning)\n",
    "6. [Results & Analysis](#6-results)\n",
    "7. [Conclusion](#7-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction & Theory <a id='1-introduction'></a>\n",
    "\n",
    "### 1.1 Project Overview\n",
    "\n",
    "This project implements a **Support Vector Machine (SVM)** classifier for object recognition using the **CIFAR-10** dataset. SVM is a supervised learning algorithm that finds the optimal hyperplane to separate different classes.\n",
    "\n",
    "### 1.2 Support Vector Machine (SVM)\n",
    "\n",
    "SVM works by finding the hyperplane that maximizes the margin between classes:\n",
    "\n",
    "- **Linear SVM**: For linearly separable data\n",
    "- **Kernel SVM**: Uses the \"kernel trick\" for non-linear boundaries\n",
    "- **RBF Kernel**: `K(x, y) = exp(-Î³||x-y||Â²)` - creates flexible decision boundaries\n",
    "\n",
    "### 1.3 HOG Feature Extraction\n",
    "\n",
    "**Histogram of Oriented Gradients (HOG)** captures edge and gradient structure:\n",
    "\n",
    "1. Compute gradients in x and y directions\n",
    "2. Create histograms of gradient orientations in cells\n",
    "3. Normalize histograms across blocks\n",
    "4. Concatenate to form feature vector\n",
    "\n",
    "### 1.4 CIFAR-10 Dataset\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| Total Images | 60,000 |\n",
    "| Training Set | 50,000 |\n",
    "| Test Set | 10,000 |\n",
    "| Image Size | 32Ã—32 RGB |\n",
    "| Classes | 10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Import project modules\n",
    "from data_loader import load_cifar10, preprocess_images, CLASS_NAMES, get_class_distribution\n",
    "from feature_extraction import HOGFeatureExtractor, visualize_hog_features\n",
    "from svm_classifier import SVMClassifier\n",
    "from visualization import (\n",
    "    plot_sample_images, plot_class_distribution, plot_confusion_matrix,\n",
    "    plot_roc_curves, plot_prediction_samples, plot_metrics_comparison,\n",
    "    plot_per_class_accuracy, plot_hog_visualization\n",
    ")\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print('âœ“ All imports successful!')\n",
    "print(f'âœ“ Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Loading & Exploration <a id='2-data-loading'></a>\n",
    "\n",
    "### 2.1 Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (using subset for faster execution)\n",
    "# Change subset_size to None for full dataset\n",
    "SUBSET_SIZE = 10000  # Use 10,000 samples for demonstration\n",
    "\n",
    "data = load_cifar10(data_dir='../data', subset_size=SUBSET_SIZE)\n",
    "\n",
    "# Extract data\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "\n",
    "print(f'\\nðŸ“Š Dataset Summary:')\n",
    "print(f'   Training samples: {len(X_train):,}')\n",
    "print(f'   Test samples: {len(X_test):,}')\n",
    "print(f'   Image shape: {X_train.shape[1:]}')\n",
    "print(f'   Number of classes: {len(CLASS_NAMES)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from the dataset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('CIFAR-10 Sample Images (One per Class)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Find first image of class i\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    ax.imshow(X_train[idx])\n",
    "    ax.set_title(f'{CLASS_NAMES[i].capitalize()}', fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "distribution = get_class_distribution(y_train)\n",
    "\n",
    "# Create DataFrame for display\n",
    "df_dist = pd.DataFrame({\n",
    "    'Class': list(distribution.keys()),\n",
    "    'Count': list(distribution.values())\n",
    "})\n",
    "df_dist['Percentage'] = (df_dist['Count'] / df_dist['Count'].sum() * 100).round(2)\n",
    "\n",
    "print('ðŸ“Š Training Set Class Distribution:')\n",
    "print(df_dist.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, 10))\n",
    "bars = ax.bar(df_dist['Class'], df_dist['Count'], color=colors, edgecolor='white', linewidth=1.5)\n",
    "\n",
    "for bar, count in zip(bars, df_dist['Count']):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20,\n",
    "            f'{count}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Object Class', fontsize=12)\n",
    "ax.set_ylabel('Number of Images', fontsize=12)\n",
    "ax.set_title('Class Distribution in Training Set', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Feature Engineering (HOG) <a id='3-feature-engineering'></a>\n",
    "\n",
    "### 3.1 Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images: convert to grayscale and normalize\n",
    "print('Preprocessing images...')\n",
    "\n",
    "X_train_processed = preprocess_images(X_train, grayscale=True, normalize=True)\n",
    "X_test_processed = preprocess_images(X_test, grayscale=True, normalize=True)\n",
    "\n",
    "print(f'âœ“ Training images preprocessed: {X_train_processed.shape}')\n",
    "print(f'âœ“ Test images preprocessed: {X_test_processed.shape}')\n",
    "\n",
    "# Visualize preprocessing\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "idx = np.random.randint(0, len(X_train))\n",
    "\n",
    "axes[0].imshow(X_train[idx])\n",
    "axes[0].set_title(f'Original RGB - {CLASS_NAMES[y_train[idx]]}', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(X_train_processed[idx], cmap='gray')\n",
    "axes[1].set_title('Preprocessed (Grayscale, Normalized)', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle('Image Preprocessing', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 HOG Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HOG Feature Extractor\n",
    "extractor = HOGFeatureExtractor(\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(4, 4),\n",
    "    cells_per_block=(2, 2)\n",
    ")\n",
    "\n",
    "print('HOG Parameters:')\n",
    "print(f'   Orientations: {extractor.orientations}')\n",
    "print(f'   Pixels per cell: {extractor.pixels_per_cell}')\n",
    "print(f'   Cells per block: {extractor.cells_per_block}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features from training set\n",
    "X_train_features = extractor.fit_transform(X_train_processed, apply_pca=False)\n",
    "\n",
    "print(f'\\nðŸ“Š Feature Extraction Results:')\n",
    "print(f'   Input image shape: {X_train_processed[0].shape}')\n",
    "print(f'   Features per image: {X_train_features.shape[1]}')\n",
    "print(f'   Total training features: {X_train_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from test set\n",
    "X_test_features = extractor.transform(X_test_processed)\n",
    "\n",
    "print(f'âœ“ Test features: {X_test_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize HOG features for sample images\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    \n",
    "    # Original\n",
    "    axes[i, 0].imshow(X_train[idx])\n",
    "    axes[i, 0].set_title(f'Original: {CLASS_NAMES[y_train[idx]]}', fontsize=11)\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Grayscale\n",
    "    axes[i, 1].imshow(X_train_processed[idx], cmap='gray')\n",
    "    axes[i, 1].set_title('Grayscale', fontsize=11)\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # HOG\n",
    "    _, hog_image = visualize_hog_features(X_train_processed[idx], extractor)\n",
    "    axes[i, 2].imshow(hog_image, cmap='gray')\n",
    "    axes[i, 2].set_title('HOG Features', fontsize=11)\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Feature histogram\n",
    "    features = X_train_features[idx]\n",
    "    axes[i, 3].hist(features, bins=50, color='steelblue', edgecolor='white', alpha=0.7)\n",
    "    axes[i, 3].set_title(f'Feature Distribution ({len(features)} dims)', fontsize=11)\n",
    "    axes[i, 3].set_xlabel('Feature Value')\n",
    "    axes[i, 3].set_ylabel('Frequency')\n",
    "\n",
    "plt.suptitle('HOG Feature Extraction Pipeline', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Model Training <a id='4-model-training'></a>\n",
    "\n",
    "### 4.1 Train SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVM classifier\n",
    "classifier = SVMClassifier(\n",
    "    kernel='rbf',\n",
    "    C=10.0,\n",
    "    gamma='scale'\n",
    ")\n",
    "\n",
    "# Train\n",
    "classifier.train(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Initial Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "results = classifier.evaluate(X_test_features, y_test, class_names=CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Hyperparameter Tuning <a id='5-hyperparameter-tuning'></a>\n",
    "\n",
    "### 5.1 Grid Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid (simplified for speed)\n",
    "param_grid = {\n",
    "    'C': [1, 10],\n",
    "    'gamma': ['scale', 0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Initialize new classifier for tuning\n",
    "tuned_classifier = SVMClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "best_params = tuned_classifier.tune_hyperparameters(\n",
    "    X_train_features, \n",
    "    y_train,\n",
    "    param_grid=param_grid,\n",
    "    cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned model\n",
    "tuned_results = tuned_classifier.evaluate(X_test_features, y_test, class_names=CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Results & Analysis <a id='6-results'></a>\n",
    "\n",
    "### 6.1 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tuned results\n",
    "final_results = tuned_results\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Score': [\n",
    "        f\"{final_results['accuracy']*100:.2f}%\",\n",
    "        f\"{final_results['precision']*100:.2f}%\",\n",
    "        f\"{final_results['recall']*100:.2f}%\",\n",
    "        f\"{final_results['f1_score']*100:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print('\\n' + '='*50)\n",
    "print('ðŸ“Š FINAL MODEL PERFORMANCE')\n",
    "print('='*50)\n",
    "print(summary.to_string(index=False))\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, final_results['y_pred'])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontweight='bold')\n",
    "\n",
    "# Normalized\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(CLASS_NAMES)))\n",
    "\n",
    "for i, (class_idx, data) in enumerate(final_results['roc_data'].items()):\n",
    "    ax.plot(data['fpr'], data['tpr'], color=colors[i], lw=2,\n",
    "            label=f\"{CLASS_NAMES[class_idx]} (AUC = {data['auc']:.3f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=1.5, label='Random Classifier')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves (One-vs-Rest)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "class_accuracies = []\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    mask = y_test == i\n",
    "    if mask.sum() > 0:\n",
    "        acc = (final_results['y_pred'][mask] == i).sum() / mask.sum()\n",
    "    else:\n",
    "        acc = 0\n",
    "    class_accuracies.append(acc * 100)\n",
    "\n",
    "# Create DataFrame\n",
    "df_class_acc = pd.DataFrame({\n",
    "    'Class': CLASS_NAMES,\n",
    "    'Accuracy (%)': [f'{acc:.1f}%' for acc in class_accuracies]\n",
    "})\n",
    "\n",
    "print('\\nðŸ“Š Per-Class Accuracy:')\n",
    "print(df_class_acc.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = plt.cm.RdYlGn(np.array(class_accuracies) / 100)\n",
    "bars = ax.bar(CLASS_NAMES, class_accuracies, color=colors, edgecolor='white', linewidth=1.5)\n",
    "\n",
    "for bar, acc in zip(bars, class_accuracies):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "            f'{acc:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlabel('Object Class', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Per-Class Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=np.mean(class_accuracies), color='blue', linestyle='--', \n",
    "           alpha=0.7, label=f'Mean: {np.mean(class_accuracies):.1f}%')\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample predictions\n",
    "n_samples = 15\n",
    "indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "fig.suptitle('Model Predictions on Test Images', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, ax in zip(indices, axes.flat):\n",
    "    ax.imshow(X_test[idx])\n",
    "    \n",
    "    true_label = CLASS_NAMES[y_test[idx]]\n",
    "    pred_label = CLASS_NAMES[final_results['y_pred'][idx]]\n",
    "    is_correct = y_test[idx] == final_results['y_pred'][idx]\n",
    "    \n",
    "    color = 'green' if is_correct else 'red'\n",
    "    symbol = 'âœ“' if is_correct else 'âœ—'\n",
    "    \n",
    "    ax.set_title(f'{symbol} Pred: {pred_label}\\nTrue: {true_label}',\n",
    "                fontsize=9, color=color, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Conclusion <a id='7-conclusion'></a>\n",
    "\n",
    "### 7.1 Summary\n",
    "\n",
    "This project successfully implemented an **SVM-based object recognition system** using the CIFAR-10 dataset.\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **HOG features** effectively capture edge and gradient information for object recognition\n",
    "2. **RBF kernel SVM** provides flexible non-linear decision boundaries\n",
    "3. **Hyperparameter tuning** improves model performance\n",
    "4. Some classes (e.g., ships, trucks) are easier to classify than others (cats, dogs)\n",
    "\n",
    "### 7.2 Comparison to Other Methods\n",
    "\n",
    "| Method | Expected Accuracy on CIFAR-10 |\n",
    "|--------|------------------------------|\n",
    "| Random Baseline | 10% |\n",
    "| **HOG + SVM (this project)** | **55-65%** |\n",
    "| CNN (AlexNet) | ~82% |\n",
    "| CNN (ResNet) | ~93% |\n",
    "| State-of-the-art | 99%+ |\n",
    "\n",
    "### 7.3 Future Work\n",
    "\n",
    "- Try different feature extraction methods (SIFT, SURF)\n",
    "- Experiment with feature combination\n",
    "- Implement ensemble methods\n",
    "- Compare with CNN-based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import os\n",
    "os.makedirs('../outputs/models', exist_ok=True)\n",
    "\n",
    "tuned_classifier.save('../outputs/models/svm_classifier.joblib')\n",
    "extractor.save('../outputs/models/feature_extractor.joblib')\n",
    "\n",
    "print('\\nâœ“ Models saved successfully!')\n",
    "print('\\nðŸŽ“ Project Complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
